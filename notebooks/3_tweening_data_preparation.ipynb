{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Producing tweening datasets** <br>\n",
    "This notebook describes the process of creating a dataset for tweening, or temporal gap filling. The tweening dataset consists of hourly stacked full tile inputs and is  <u>created from the data  you have downloaded and preprocessed</u> using the [download](./4_download_data.ipynb) and [preprocess](./5_preprocess_data.ipynb) workflows. \n",
    "\n",
    "Please ensure the data directories set below have valid HLS and ERA5 hourly datasets. \n",
    "\n",
    "Activate the environment created in the [Getting Started Notebook](./1_getting_started.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "import tqdm\n",
    "from utils.tweening import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set data parameters for single tile acquisition you would like to create a tweening dataset for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = \"../data/processed_data/\"   #path to processed hls data and lsts\n",
    "city_iso = \"johannesburg_zaf\"\n",
    "hls_date = \"20211103\"   # choose a date from data you have preprocessed\n",
    "tile_id = \"T35JNM\"      \n",
    "tweening_period = 7     # days to tween for\n",
    "\n",
    "# path to save stacked hourly inputs\n",
    "data_directory = os.path.join(\"../data/processed_tweening_data/\")\n",
    "if os.path.exists(data_directory)==False:\n",
    "    os.mkdir(data_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Replicate the HLS bands for every hour of the tweening period selected and stack these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather hls bands for date and tile_id\n",
    "\n",
    "band_string = os.path.join(processed_data_path, \"hls-bands/\") + city_iso + \".\" + tile_id + \".\" + hls_date + \"*.tif\"\n",
    "hls_bands = sorted(glob.glob(band_string))\n",
    "\n",
    "# Gather corresponding lst file\n",
    "\n",
    "lst_string = os.path.join(processed_data_path, \"target-lst/\") + city_iso + \".\" + tile_id + \".\" + hls_date + \"*.tif\"\n",
    "lst_band = glob.glob(lst_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process lst band to get grid for inputs\n",
    "\n",
    "lst_array, grid_out, meta, crs = process_target_band(lst_band[0]) #[0] assuming there is only one lst file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract arrays from individual hls bands\n",
    "\n",
    "processed_bands = process_hls_bands(hls_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack these arrays\n",
    "\n",
    "stacked = stacking(processed_bands, grid_out, crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the first stacked geotiff\n",
    "\n",
    "file_name = city_iso + \".\" + tile_id + \".\" + hls_date + \".T000000.input_file.tif\"\n",
    "save_file = os.path.join(data_directory, file_name)\n",
    "stacked.rio.to_raster(save_file, driver=\"COG\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate for every hour in tweening period\n",
    "\n",
    "duplicate_hls_bands(save_file, hls_date, tweening_period, data_directory, city_iso, tile_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Include hourly ERA5 2m_temperature data for every input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather input files\n",
    "\n",
    "files_to_update = glob.glob(os.path.join(data_directory, \"*.input_file.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather ERA5 files for city\n",
    "\n",
    "era5_dir = \"../data/downloaded_data/era5/\"\n",
    "era5_cities, all_era5_inputs = files_extractor(era5_dir)\n",
    "era5_city = filter_city(city_name=city_iso, lst=all_era5_inputs)\n",
    "\n",
    "# reduce the ERA5 data - filter for the year you are considering\n",
    "\n",
    "era5_city_year = filter_year(year= hls_date[0:4], files = era5_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b952880cd48743ed9d7af4d8e3749c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update input file with ERA5 bands\n",
    "\n",
    "with tqdm(total=len(files_to_update)) as pbar:\n",
    "    for file in files_to_update:\n",
    "        add_era5_stack(file, city_iso, grid_out, crs, era5_city_year)\n",
    "        # remove HLS only stacked input \n",
    "        os.remove(file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. You are now able to run inference on the granite-geospatial-land-surface-temperature model using these hourly stacked-tiles\n",
    "\n",
    "Refer to the [Getting Started Notebook](./1_getting_started.ipynb) and the [introduction to LST Tweening](./2_introduction_to_LST_Tweening.ipynb) notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
